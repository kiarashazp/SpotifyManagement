services:
  eventsim:
    image: khoramism/event-generator-eventsim:1.2
    environment:
      - BOOTSTRAP_SERVERS=broker:29092
      - SECURITY_PROTOCOL=PLAINTEXT
      - SASL_JAAS_CONFIG=''
      - SASL_MECHANISM=''
      - CLIENT_DNS_LOOKUP=use_all_dns_ips
      - SESSION_TIMEOUT_MS=45000
      - KEY_SERIALIZER=org.apache.kafka.common.serialization.ByteArraySerializer
      - VALUE_SERIALIZER=org.apache.kafka.common.serialization.ByteArraySerializer
      - SCHEMA_REGISTRY_URL=http://schema-registry:8085
      - ACKS=all
    ports:
      - "8083:8083"
    volumes:
      - ../eventsim/examples:/eventsim/examples
    working_dir: /eventsim
    command: ./bin/eventsim -c configs/Guitar-config.json --continuous --from 200 --nusers 2000 -k 1
    depends_on:
      broker:
        condition: service_healthy
    networks:
      - data-highway

  broker:
    image: apache/kafka:latest
    hostname: broker
    container_name: broker
    ports:
      - 9092:9092
    shm_size: "2GB"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@broker:29093
      KAFKA_LISTENERS: PLAINTEXT://broker:29092,CONTROLLER://broker:29093,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LOG_DIRS: /kafka-logs
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk
      KAFKA_MESSAGE_MAX_BYTES: 1073741824  # 1GB
      KAFKA_REPLICA_FETCH_MAX_BYTES: 1073741824  # 1GB
      KAFKA_FETCH_MESSAGE_MAX_BYTES: 1073741824  # 1GB
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 1073741824  # 1GB
    volumes:
      - ../kafka-logs:/kafka-logs
    # user: "1000:1000"
    user: "root"
    networks:
      - data-highway
    healthcheck:
      test: ["CMD", "nc", "-z", "broker", "9092"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 60s
    depends_on:
      namenode:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: "4G"

  kafka-exporter:
    image: danielqsj/kafka-exporter:latest
    command: ["--kafka.server=broker:29092"]
    ports:
      - "9308:9308"
    depends_on:
      broker:
        condition: service_healthy
    networks:
      data-highway:
        aliases:
          - kafka-exporter

  akhq:
    image: tchiotludo/akhq
    restart: unless-stopped
    environment:
      AKHQ_CONFIGURATION: |
        akhq:
          connections:
            docker-kafka-server:
              properties:
                bootstrap.servers: "broker:29092"
              schema-registry:
                url: "http://schema-registry:8085"
    ports:
      - "9090:8080"
    depends_on:
      - broker
      - schema-registry
    networks:
      - data-highway

  schema-registry:
    image: confluentinc/cp-schema-registry:latest
    restart: unless-stopped
    depends_on:
      - broker
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'PLAINTEXT://broker:29092'
      SCHEMA_REGISTRY_LISTENERS: 'http://0.0.0.0:8085'
      SCHEMA_REGISTRY_HOST_NAME: 'schema-registry'
    networks:
      - data-highway
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://schema-registry:8085/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  schema-registry-init:
    image: confluentinc/cp-schema-registry:latest
    volumes:
      - ./sr-entrypoint.sh:/scripts/entrypoint.sh
      - /schema-registry/json:/schemas/json
    restart: on-failure
    depends_on:
      schema-registry:
        condition: service_healthy
    entrypoint: ["/scripts/entrypoint.sh"]
    networks:
      - data-highway

  spark:
    image: docker.io/bitnami/spark:3.5
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
      - SPARK_MASTER_OPTS=-javaagent:/opt/bitnami/spark/jars/jmx_prometheus_javaagent.jar=7072:/opt/bitnami/spark/conf/jmx_exporter.yml
    ports:
      - '8081:8081'  # Spark Master UI
      - '10000:10000'  # For Thrift server
      - '7077:7077'    # For Spark master
    volumes:
      - ../spark/bronze_ingest.py:/opt/bitnami/scripts/bronze_ingest.py
      - ../jmx-exporters/spark-jmx-exporter-config.yml:/opt/bitnami/spark/conf/jmx_exporter.yml
      - ../jmx-exporters/jmx_prometheus_javaagent-1.0.1.jar:/opt/bitnami/spark/jars/jmx_prometheus_javaagent.jar
      - ./spark-entrypoint.sh:/opt/bitnami/scripts/spark-entrypoint.sh
    networks:
      data-highway:
        aliases:
          - spark
    entrypoint: ["/bin/bash", "/opt/bitnami/scripts/spark-entrypoint.sh"]

  spark-worker:
    image: docker.io/bitnami/spark:3.5
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
      - SPARK_WORKER_OPTS=-javaagent:/opt/bitnami/spark/jars/jmx_prometheus_javaagent.jar=7073:/opt/bitnami/spark/conf/jmx_exporter.yml
    depends_on:
      - spark
    ports:
      - '8082:8081'
      - '7073:7073'  # JMX Exporter port
    volumes:
      - ../jmx-exporters/spark-jmx-exporter-config.yml:/opt/bitnami/spark/conf/jmx_exporter.yml
      - ../jmx-exporters/jmx_prometheus_javaagent-1.0.1.jar:/opt/bitnami/spark/jars/jmx_prometheus_javaagent.jar
    networks:
      data-highway:
        aliases:
          - spark-worker
    command: /opt/bitnami/spark/sbin/start-worker.sh spark://spark:7077

  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: always
    ports:
      - 9870:9870
      - 9000:9000
      - 7074:7074  # JMX Exporter port
    volumes:
      - ../hadoop/hadoop_namenode:/hadoop/dfs/name
      - ../hadoop/conf/hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
      - ../jmx-exporters/jmx_prometheus_javaagent-1.0.1.jar:/opt/hadoop/jmx_prometheus_javaagent.jar
      - ../jmx-exporters/hdfs-jmx-exporter-config.yml:/opt/hadoop/conf/jmx_exporter.yml
    environment:
      - CLUSTER_NAME=test
      - HADOOP_OPTS=-javaagent:/opt/hadoop/jmx_prometheus_javaagent.jar=7074:/opt/hadoop/conf/jmx_exporter.yml
    env_file:
      - ../hadoop/hadoop.env
    networks:
      data-highway:
        aliases:
          - namenode
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9870"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    restart: always
    depends_on:
      - namenode
    volumes:
      - ../hadoop/hadoop_datanode:/hadoop/dfs/data
      - ../hadoop/conf/hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
      - ../jmx-exporters/jmx_prometheus_javaagent-1.0.1.jar:/opt/hadoop/jmx_prometheus_javaagent.jar
      - ../jmx-exporters/hdfs-jmx-exporter-config.yml:/opt/hadoop/conf/jmx_exporter.yml
    environment:
      - SERVICE_PRECONDITION=namenode:9870
      - HADOOP_OPTS=-javaagent:/opt/hadoop/jmx_prometheus_javaagent.jar=7075:/opt/hadoop/conf/jmx_exporter.yml
    ports:
      - 9864:9864
      - 7075:7075  # JMX Exporter port
    env_file:
      - ../hadoop/hadoop.env
    networks:
      data-highway:
        aliases:
          - datanode

  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: resourcemanager
    restart: always
    environment:
      - SERVICE_PRECONDITION=namenode:9000 namenode:9870 datanode:9864
      - HADOOP_OPTS=-javaagent:/opt/hadoop/jmx_prometheus_javaagent.jar=7076:/opt/hadoop/conf/jmx_exporter.yml
    ports:
      - 8088:8088
      - 7076:7076  # JMX Exporter port
    volumes:
      - ../jmx-exporters/hdfs-jmx-exporter-config.yml:/opt/hadoop/conf/jmx_exporter.yml
      - ../jmx-exporters/jmx_prometheus_javaagent-1.0.1.jar:/opt/hadoop/jmx_prometheus_javaagent.jar
    env_file:
      - ../hadoop/hadoop.env
    networks:
      data-highway:
        aliases:
          - resourcemanager

  nodemanager1:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager
    restart: always
    environment:
      - SERVICE_PRECONDITION=namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088
      - HADOOP_OPTS=-javaagent:/opt/hadoop/jmx_prometheus_javaagent.jar=7077:/opt/hadoop/conf/jmx_exporter.yml
    ports:
      - 8042:8042
      - 17077:7077
    volumes:
      - ../jmx-exporters/hdfs-jmx-exporter-config.yml:/opt/hadoop/conf/jmx_exporter.yml
      - ../jmx-exporters/jmx_prometheus_javaagent-1.0.1.jar:/opt/hadoop/jmx_prometheus_javaagent.jar
    env_file:
      - ../hadoop/hadoop.env
    networks:
      data-highway:
        aliases:
          - nodemanager

  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: historyserver
    restart: always
    environment:
      - SERVICE_PRECONDITION=namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088
      - HADOOP_OPTS=-javaagent:/opt/hadoop/jmx_prometheus_javaagent.jar=7078:/opt/hadoop/conf/jmx_exporter.yml
    ports:
      - 8188:8188
      - 7078:7078  # JMX Exporter port
    volumes:
      - ../hadoop/hadoop_historyserver:/hadoop/yarn/timeline
      - ../jmx-exporters/jmx_prometheus_javaagent-1.0.1.jar:/opt/hadoop/jmx_prometheus_javaagent.jar
      - ../jmx-exporters/hdfs-jmx-exporter-config.yml:/opt/hadoop/conf/jmx_exporter.yml
    env_file:
      - ../hadoop/hadoop.env
    networks:
      data-highway:
        aliases:
          - historyserver

  # Add ClickHouse
  clickhouse-server:
    image: clickhouse/clickhouse-server:latest
    container_name: clickhouse-server
    restart: always
    ports:
      - "8123:8123"  # HTTP port
      - "9001:9000"  # Native port
      - "9009:9009"
    volumes:
      - ../clickhouse/data:/var/lib/clickhouse

    environment:
      # Add environment variables for basic configuration
      - CLICKHOUSE_DB=spotify
      - CLICKHOUSE_USER=default
      - CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    networks:
      data-highway:
        aliases:
          - clickhouse-server
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8123/ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  clickhouse-exporter:
    image: f1yegor/clickhouse-exporter:latest
    container_name: clickhouse-exporter
    restart: always
    ports:
      - '9116:9116'
    command: ["-scrape_uri=http://clickhouse-server:8123/?query=select+metric%2C+value+from+system.metrics"]
    networks:
      data-highway:
        aliases:
          - clickhouse-exporter

  # Add dbt with HDFS support
  dbt:
    image: fishtownanalytics/dbt:1.0.0
    container_name: dbt
    volumes:
      - ../dbt:/usr/app
      - ../hadoop/conf:/etc/hadoop/conf
      - ./dbt-entrypoint.sh:/entrypoint.sh
      # Add direct access to Hadoop configurations
      - ../hadoop/hadoop.env:/etc/hadoop/hadoop.env
    working_dir: /usr/app
    depends_on:
      - spark
      - namenode
      - datanode
      - resourcemanager
    networks:
      - data-highway
    environment:
      - DBT_PROFILES_DIR=/usr/app/profiles
      - HADOOP_CONF_DIR=/etc/hadoop/conf
      - HADOOP_USER_NAME=root
      - SPARK_HOME=/usr/local/spark
      - PYTHONPATH=/usr/local/spark/python:/usr/local/spark/python/lib/py4j-0.10.9-src.zip
    entrypoint: ["/bin/bash", "/entrypoint.sh"]
    # Keep the container running
    tty: true
    stdin_open: true

  postgres-metabase:
    image: postgres:13
    container_name: postgres-metabase
    hostname: postgres
    restart: always
    environment:
      - POSTGRES_USER=metabase
      - POSTGRES_PASSWORD=mysecretpassword
      - POSTGRES_DB=metabaseappdb
    volumes:
      - ../postgres-metabase-data:/var/lib/postgresql/data
      - ./init-metabase-db.sh:/docker-entrypoint-initdb.d/init-metabase-db.sh
    ports:
      - "5433:5432"  # Using 5433 externally to avoid conflict with Hive's PostgreSQL
    networks:
      - data-highway
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U metabase"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Metabase with ClickHouse driver
  metabase:
    image: lucasluanp/metabase-with-clickhouse
    container_name: metabase
    hostname: metabase
    volumes:
      - /dev/urandom:/dev/random:ro
    ports:
      - 3001:3001
    environment:
      MB_DB_TYPE: postgres
      MB_DB_DBNAME: metabaseappdb
      MB_DB_PORT: 5432
      MB_DB_USER: metabase
      MB_DB_PASS: mysecretpassword
      MB_DB_HOST: postgres-metabase
      MB_JETTY_PORT: 3001
    networks:
      - data-highway
    depends_on:
      postgres-metabase:
        condition: service_healthy
      clickhouse-server:
        condition: service_started
    healthcheck:
      test: curl --fail -I http://localhost:3001/api/health || exit 1
      interval: 15s
      timeout: 5s
      retries: 5

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9099:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - ./prometheus_alerts.yml:/etc/prometheus/prometheus_alerts.yml
      - ./clickhouse_clerts.yml:/etc/prometheus/clickhouse_alerts.yml
    networks:
      - data-highway

  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    restart: unless-stopped
    ports:
      - "9100:9100"
    networks:
      - data-highway

  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    restart: unless-stopped
    ports:
      - "9093:9093"
    volumes:
      - ./alertmanager.yml:/etc/alertmanager/alertmanager.yml
      - ./telegram.tmpl:/etc/alertmanager/telegram.tmpl


  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    volumes:
      - grafana-storage:/var/lib/grafana
    networks:
      - data-highway

volumes:
  kafka-data:
  grafana-storage:
  hadoop_namenode:
  hadoop_datanode:
  hadoop_historyserver:
  postgres-metabase-data:
  metabase-data:
  clickhouse-data:


networks:
  data-highway:
    driver: bridge
